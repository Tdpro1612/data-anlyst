{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "[Team 5] Global Terrorism.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHMb6-FIg-xH",
        "colab_type": "text"
      },
      "source": [
        "# Team 5 - Global Terrorism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOR7TfKdCFfr",
        "colab_type": "text"
      },
      "source": [
        "### What is your data about?\n",
        "Information on 180,000 terrorist attacks\n",
        "Around the world from 1970 through 2017. \n",
        "- It includes systematic data on domestic as well as international terrorist. \n",
        "- There are no plots, conspiracies and unsuccessful attacks. \n",
        "\n",
        "### Target Audience: \n",
        "- Business Invester who want to find a safe place to invest their money without the fear about terrorist attacks.\n",
        "\n",
        "### Data details\n",
        "- Incidents location\n",
        "- Date and time the incident happened\n",
        "- Incident information\n",
        "  - Attack type\n",
        "  - Attack target\n",
        "  - Group of Perpetrator \n",
        "  - Incident Motive\n",
        "\n",
        "### Evaluation metrics\n",
        "Based on 2 metrics\n",
        "- Casualties: a combination of killed and wounded victims\n",
        "- Damaged Property value: the estimation of damaged property by USD.\n",
        "\n",
        "### Hypothesis:\n",
        "- Which is the most countries was aim by terrorism?\n",
        "- Where is the most dangerous place to to stay in terms of terrorism?\n",
        "- Where is the place we can get least damage from a terrorist attack?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Exploration ideas:\n",
        "- The rise of all terrorism around the world\n",
        "- Top 10 nationality of target victim and a casuality \n",
        "- Top 10 Countries that most affected by terrorism\n",
        "- Top 10 terrorism Activities by Type of attack and target\n",
        "- What is the common motive of all kind terrorism in the world\n",
        "- Top 10 Terrorist Groups with Highest Terror Attacks\n",
        "- Growth of damaged property value and casuality of US\n",
        "- Which US target that was attacked mostly?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBP6c4qNVByN",
        "colab_type": "text"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slEacVLEg-xL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2d6df3bb-9351-4014-ddbd-371faf41e7f4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prUCvuvDVOxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euovg9MHs8cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill the blanks\n",
        "terr = pd.read_csv('drive/My Drive/FTMLE - Tonga/Week_3/assignments/datasets/05-global-terrorism/terrorism.csv',encoding='latin-1')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N20fAx_ss8Rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a summary of the data\n",
        "terr.info()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q13AizaK-nI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a sample\n",
        "terr.sample(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoiXtewf_C_g",
        "colab_type": "text"
      },
      "source": [
        "# Clean data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVuFqnmyMJhA",
        "colab_type": "text"
      },
      "source": [
        "### Check data duplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agnoTUsrMQ2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if ID column is unique\n",
        "terr['eventid'].nunique() == terr.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xYsHK3Mu1l",
        "colab_type": "text"
      },
      "source": [
        "### Rename used columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-idcD7v_F1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rename used columns\n",
        "terr.rename(columns={'iyear':'Year','imonth':'Month','propvalue':'DamagedPropertyValue',\n",
        "                       'iday':'Day','country_txt':'Country','latitude':'Latitude','longitude':'Longitude',\n",
        "                       'region_txt':'Region','attacktype1_txt':'AttackType','city':'City',\n",
        "                       'target1':'Target','nkill':'Killed','nkillus':'KilledUS',\n",
        "                       'nwound':'Wounded','nwoundus':'WoundedUS','eventid':'ID',\n",
        "                       'gname':'Group','targtype1_txt':'TargetType','natlty1_txt':'TargetNationality',\n",
        "                       'weaptype1_txt':'WeaponType','motive':'Motive'},inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20YVFaMIM9pA",
        "colab_type": "text"
      },
      "source": [
        "### Get used columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb7JsjSYBve_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get columns\n",
        "terr=terr[['Year','Month','Day','Country',\n",
        "           'Region','City','WoundedUS',\n",
        "           'KilledUS','AttackType','ID','Latitude','Longitude',\n",
        "           'Killed','Wounded','Target','DamagedPropertyValue',\n",
        "           'Group','TargetType','WeaponType',\n",
        "           'Motive','TargetNationality']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtB5k_jduB8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop data before 1997\n",
        "terr.drop(labels=terr[terr['Year'] < 1997].index, axis=0, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHilqV_TiN2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show a summary of the data \n",
        "terr.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8jfpWakO3A2",
        "colab_type": "text"
      },
      "source": [
        "### Manipulate **data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "daLhjYReTz7a",
        "colab": {}
      },
      "source": [
        "# Check for missing data\n",
        "terr.isnull().sum()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k_gbEXKPT09X",
        "colab": {}
      },
      "source": [
        "# Fill NaN to city, Target, Summary, Motive\n",
        "terr['City'].fillna(\"Unknown\", inplace=True)\n",
        "terr['Target'].fillna(\"Unknown\", inplace=True)\n",
        "terr['Region'] = terr['Region'].astype('category')\n",
        "terr['Motive'].fillna(\"Unknown\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYZvo-V0PQDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill NaN to 0 for Killed and Wounded\n",
        "terr['Killed'].fillna(0, inplace=True)\n",
        "terr['Killed'] = terr['Killed'].astype(int) \n",
        "terr['Wounded'].fillna(0, inplace=True)\n",
        "terr['Wounded'] = terr['Wounded'].astype(int) \n",
        "terr['KilledUS'].fillna(0, inplace=True)\n",
        "terr['KilledUS'] = terr['KilledUS'].astype(int)\n",
        "terr['WoundedUS'].fillna(0, inplace=True)\n",
        "terr['WoundedUS'] = terr['WoundedUS'].astype(int)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhP5B0U5yW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill NaN to Nationality False\n",
        "terr['TargetNationality'].fillna(\"No data\", inplace=True)\n",
        "terr['TargetNationality'] = terr['TargetNationality'].astype('category')\n",
        "\n",
        "# File NaN to Property Damage\n",
        "terr['DamagedPropertyValue'].fillna(0, inplace=True)\n",
        "terr['DamagedPropertyValue'] = terr['DamagedPropertyValue'].apply(lambda x: 0 if x < 0 else x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hfkyLMcfIJs",
        "colab": {}
      },
      "source": [
        "# Change data type\n",
        "terr['Country'] = terr['Country'].astype('category')\n",
        "terr['City'] = terr['Country'].astype('category')\n",
        "terr['Group'] = terr['Group'].astype('category')\n",
        "terr['WeaponType'] = terr['WeaponType'].astype('category')\n",
        "terr['Target'] = terr['Target'].astype('category')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK6174o3dM06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terr[terr['Latitude'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf25WEGsmLMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for missing data\n",
        "terr.info()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eH6pcINB2O",
        "colab_type": "text"
      },
      "source": [
        "#### Add casualties column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHd6kK6dhflC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add casualities\n",
        "terr['Casualities']= terr['Killed']+terr['Wounded']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPXi0xghI8kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IsSuccessfull = (terr['Casualities'] > 0) + (terr['DamagedPropertyValue'] > 0)\n",
        "IsSuccessfull.value_counts()\n",
        "terr['IsSuccessfull'] = IsSuccessfull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLou-G2O5vgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terr.groupby('Country')['Casualities'].mean().sort_values().head(40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CQyepie7W2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create new ID\n",
        "terr.drop(columns=[\"ID\"], inplace=True)\n",
        "terr.reset_index(drop=True, inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUj9e_y_hJD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terr.sample(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvX_dH885aFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export to csv file\n",
        "terr.to_csv('/content/sample_data/clean_terrorism.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSt8mVx1NJWU",
        "colab_type": "text"
      },
      "source": [
        "## Exploration data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfPWCG9dNt6_",
        "colab_type": "text"
      },
      "source": [
        "### The rise of all terrorism around the world"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwAKhI3QNkLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of terrorism around the world from 1997 to 2017 \n",
        "plt.figure(figsize=(15,6))\n",
        "ax = sns.countplot(x='Year', data=terr, color='red')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJXL8QSeOO17",
        "colab_type": "text"
      },
      "source": [
        "### Top 10 nationality of target victim and a casuality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3tYTIdDOcD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select 10 nationalities have most victim\n",
        "top10_casuality = terr.groupby('TargetNationality').sum().sort_values('Casualities', ascending = False).head(10)['Casualities']\n",
        "# Plot\n",
        "top10_casuality.plot.bar(color = \"red\",figsize = (20,6))\n",
        "plt.ylabel('Casuality per person')\n",
        "plt.title('10 nationalities have most victims')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_OLo6NNK5BZ",
        "colab_type": "text"
      },
      "source": [
        "### Top 10 Countries that most affected by terrorism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H0wUnWNwK9qZ",
        "colab": {}
      },
      "source": [
        "#top 10 Countries that most affected by terrorism\n",
        "top10country = terr.groupby('Country', as_index=False)['DamagedPropertyValue'].sum().sort_values('DamagedPropertyValue', ascending=False).head(10)\n",
        "top10country['DamagedPropertyValue'] = top10country['DamagedPropertyValue'] // 1000000\n",
        "top10country['DamagedPropertyValue'] = top10country['DamagedPropertyValue'].apply(np.ceil)\n",
        "ax = top10country.plot(kind='bar', colors='red',figsize=(15,6))\n",
        "\n",
        "ax.set_xticklabels(top10country['Country'], rotation=90, ha=\"center\")\n",
        "ax.set_ylabel(\"Millions\")\n",
        "ax.set_yticklabels(np.arange(0,450,50))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wtxZrR7OCuU",
        "colab_type": "text"
      },
      "source": [
        "### Top 10 terrorism Activities by Attack Type and target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TZ5fKa7sBH0n",
        "colab": {}
      },
      "source": [
        "# Display the number of case for each target type\n",
        "plt.figure(figsize=(20,6))\n",
        "terr['TargetType'].value_counts().sort_values().head(10).plot.barh(color=\"red\")\n",
        "plt.xlabel('Cases')\n",
        "plt.ylabel('Type')\n",
        "plt.title('Target type of terrorism')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A9cLvgu-VTaI",
        "colab": {}
      },
      "source": [
        "# number of all AttackType for terrorism\n",
        "plt.figure(figsize=(15,6))\n",
        "ax = sns.countplot(x=\"AttackType\", data=terr, color='red')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m71qcfWOKW2",
        "colab_type": "text"
      },
      "source": [
        "### What is the common motive of all kind terrorism in the world\n",
        "#### Simple word filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMtHhvsjOa38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import wordcloud\n",
        "\n",
        "\n",
        "# Pick out text from \"Motive\" column\n",
        "motive_text = terr['Motive'].tolist()\n",
        "\n",
        "# Keep only alphabet characters\n",
        "regex = re.compile('[^A-Za-z0-9\\s]+')\n",
        "whole_text = ' '.join(motive_text)\n",
        "whole_text = re.sub(regex, '', whole_text)\n",
        "whole_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkikaEtaIKt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_frequencies(file_contents):\n",
        "    # List of uninteresting words\n",
        "    uninteresting_words = [\"the\", \"a\", \"to\", \"if\", \"is\", \"it\", \"of\", \"and\", \"or\", \"an\", \"as\", \"i\", \"me\", \"my\", \\\n",
        "    \"we\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"she\", \"him\", \"his\", \"her\", \"hers\", \"its\", \"they\", \"them\", \\\n",
        "    \"their\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \\\n",
        "    \"have\", \"may\",\"has\", \"had\", \"do\", \"does\", \"did\", \"but\", \"at\", \"by\", \"with\", \"from\", \"here\", \"when\", \"where\", \"how\", \\\n",
        "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"some\", \"such\", \"no\", \"nor\", \"too\", \"very\", \"can\", \"will\", \"just\", \\\n",
        "    \"in\", \"not\", \"for\", \"should\", \"would\", \"so\", \"shall\", \"on\", \"thou\", \"thee\", \"thy\", \"than\", \"s\",\"d\", \"o\", \"ll\", \"unknown\",\"specific\", \\\n",
        "    \"motive\",\"attack\",\"however\",\"noted\",\"claimed\",\"stated\",\"sources\",\"noted\",\"targeted\",\"incident\",\"carried\",\"responsibility\",\"out\",\\\n",
        "    \"part\",\"violence\",\"because\",\"larger\",\"part\",\"larger\",\"victims\",\"between\",\"trend\",\"against\",\"suspected\",\"members\",\"forces\",\"speculated\",\\\n",
        "    \"attacks\",\"group\",\"related\",\"security\",\"also\",\"recent\",\"victim\",\"response\",\"occured\",\"minority\",\"state\",\"accused\",\"government\"]\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    whole_text_words = whole_text.split()\n",
        "    words_filter = [word for word in whole_text_words if word.lower() not in uninteresting_words]\n",
        "    for i in words_filter:\n",
        "      if i not in result:\n",
        "        result[i] = 1\n",
        "      else:\n",
        "        result[i] += 1\n",
        "    #wordcloud\n",
        "    cloud = wordcloud.WordCloud(scale=5)\n",
        "    cloud.generate_from_frequencies(result)\n",
        "    return cloud.to_array()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_dhdaGdIOA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display wordcloud image\n",
        "myimage = calculate_frequencies(whole_text)\n",
        "plt.figure(figsize = (15,8))\n",
        "plt.imshow(myimage, interpolation = 'nearest', aspect='auto')\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyhbb6hSjWax",
        "colab_type": "text"
      },
      "source": [
        "#### NLP Word filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0MvHA8qQnxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instal dependencies\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdTZjLmRPj2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import string\n",
        "from matplotlib import rcParams\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, sent_tokenize, word_tokenize, BigramAssocMeasures,\\\n",
        "    BigramCollocationFinder, TrigramAssocMeasures, TrigramCollocationFinder\n",
        "from subprocess import check_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBmZcsOkPgkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bitrigrams(full_text, threshold=30):\n",
        "    if isinstance(full_text, str):\n",
        "        text = full_text\n",
        "    else:\n",
        "        text = \" \".join(full_text)\n",
        "    bigram_measures = BigramAssocMeasures()\n",
        "    finder = BigramCollocationFinder.from_words(text.split())\n",
        "    finder.apply_freq_filter(3)\n",
        "    bigrams = {\" \".join(words): \"_\".join(words)\n",
        "               for words in finder.above_score(bigram_measures.likelihood_ratio, threshold)}\n",
        "    return bigrams\n",
        "\n",
        "\n",
        "def replace_bitrigrams(text, bigrams):\n",
        "    if isinstance(text, str):\n",
        "        texts = [text]\n",
        "    else:\n",
        "        texts = text\n",
        "    new_texts = []\n",
        "    for t in texts:\n",
        "        t_new = t\n",
        "        for k, v in bigrams.items():\n",
        "            t_new = t_new.replace(\" \" + k + \" \", \" \" + v + \" \")\n",
        "        new_texts.append(t_new)\n",
        "    if len(new_texts) == 1:\n",
        "        return new_texts[0]\n",
        "    else:\n",
        "        return new_texts\n",
        "\n",
        "\n",
        "def process_text(text, lemmatizer, translate_table, stopwords):\n",
        "    processed_text = \"\"\n",
        "    for sentence in sent_tokenize(text):\n",
        "        tagged_sentence = pos_tag(word_tokenize(sentence.translate(translate_table)))\n",
        "        for word, tag in tagged_sentence:\n",
        "            word = word.lower()\n",
        "            if word not in stopwords:\n",
        "                if tag[0] != 'V':\n",
        "                    processed_text += lemmatizer.lemmatize(word) + \" \"\n",
        "    return processed_text\n",
        "\n",
        "\n",
        "def get_all_processed_texts(texts, lemmatizer, translate_table, stopwords):\n",
        "    processed_texts = []\n",
        "    for index, doc in enumerate(texts):\n",
        "        processed_texts.append(process_text(doc, wordnet_lemmatizer, translate_table, stop))\n",
        "    bigrams = get_bitrigrams(processed_texts)\n",
        "    very_processed_texts = replace_bitrigrams(processed_texts, bigrams)\n",
        "    return \" \".join(very_processed_texts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rdQyaAEQU0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "uninteresting_words = [\"the\", \"a\", \"to\", \"if\", \"is\", \"it\", \"of\", \"and\", \"or\", \"an\", \"as\", \"i\", \"me\", \"my\", \\\n",
        "    \"we\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"she\", \"him\", \"his\", \"her\", \"hers\", \"its\", \"they\", \"them\", \\\n",
        "    \"their\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \\\n",
        "    \"have\", \"may\",\"has\", \"had\", \"do\", \"does\", \"did\", \"but\", \"at\", \"by\", \"with\", \"from\", \"here\", \"when\", \"where\", \"how\", \\\n",
        "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"some\", \"such\", \"no\", \"nor\", \"too\", \"very\", \"can\", \"will\", \"just\", \\\n",
        "    \"in\", \"not\", \"for\", \"should\", \"would\", \"so\", \"shall\", \"on\", \"thou\", \"thee\", \"thy\", \"than\", \"s\",\"d\", \"o\", \"ll\", \"unknown\",\"specific\", \\\n",
        "    \"motive\",\"attack\",\"however\",\"noted\",\"claimed\",\"stated\",\"sources\",\"noted\",\"targeted\",\"incident\",\"carried\",\"responsibility\",\"out\",\\\n",
        "    \"part\",\"violence\",\"because\",\"larger\",\"part\",\"larger\",\"victims\",\"between\",\"trend\",\"against\",\"suspected\",\"members\",\"forces\",\"speculated\",\\\n",
        "    \"attacks\",\"group\",\"related\",\"security\",\"also\",\"recent\",\"victim\",\"response\",\"occured\",\"minority\",\"state\",\"accused\",\"government\"]\n",
        "stop = uninteresting_words\n",
        "stop.extend(stopwords.words('english'))\n",
        "stop = set(stop)\n",
        "translate_table = dict((ord(char), \" \") for char in string.punctuation)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFPVkG93RaTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "motive = terr[(terr['Motive'] != 'Unknown') & (terr['Motive'] != 'The specific motive for the attack is unknown.') \n",
        "          & (terr['Motive'] != 'The specific motive for the attack is unknown..')\n",
        "          & (terr['Motive'] != 'The specific motive for the attack is unknown or was not reported.')\n",
        "          & (terr['Motive'] != 'The specific motive for the attack is unknown')]\n",
        "motive = motive['Motive']\n",
        "motive.value_counts()\n",
        "print(f\"Run in {len(motive.tolist())}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I4TOo5JYzqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def use_ngrams_only(texts, lemmatizer, translate_table, stopwords):\n",
        "    processed_texts = []\n",
        "    for index, doc in enumerate(texts):\n",
        "        processed_texts.append(process_text(doc, wordnet_lemmatizer, translate_table, stop))\n",
        "    bigrams = get_bitrigrams(processed_texts)\n",
        "    indexed_texts = []\n",
        "    for doc in processed_texts:\n",
        "        current_doc = []\n",
        "        for k, v in bigrams.items():\n",
        "            current_doc += [v] * doc.count(\" \" + k + \" \")\n",
        "        indexed_texts.append(\" \".join(current_doc))\n",
        "    return \" \".join(indexed_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvGyEzxSVkQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordcloud = WordCloud(stopwords=STOPWORDS,width=1200, height=600,scale=5,collocations=False,max_words=100).\\\n",
        "    generate(use_ngrams_only(motive.tolist(), wordnet_lemmatizer, translate_table, stop))\n",
        "plt.figure(figsize = (15,8),facecolor='k')\n",
        "plt.imshow(wordcloud.to_array(), interpolation = 'nearest', aspect='auto')\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXNicu4IOMMK",
        "colab_type": "text"
      },
      "source": [
        "### Top 10 Terrorist Groups with Highest Terror Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RjvFWAUObgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Top 10 Terrorist groups with highest Terror Attacks\n",
        "\n",
        "terr_group = terr[\"Group\"].value_counts().head(11)\n",
        "terr_group = terr_group[1:]\n",
        "#Top 10 Terrorist groups with highest Terror Attacks To US\n",
        "us_terr_incidents = terr[terr['TargetNationality'] == 'United States']\n",
        "terr_group_us = us_terr_incidents[\"Group\"].value_counts().head(11)\n",
        "terr_group_us = terr_group_us[1:]\n",
        "# Plot\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "terr_group.plot(kind = \"bar\", color = \"red\")\n",
        "plt.title(\"Top 10 groups with highest attacks\")\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "\n",
        "terr_group_us.plot(kind = \"bar\", color = \"red\")\n",
        "plt.title(\"Top 10 groups with highest attacks to US\")\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwykWPQ0OQud",
        "colab_type": "text"
      },
      "source": [
        "### Growth of damaged property value and casuality of US\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPkdFG9UOc1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find damaged property value of US\n",
        "us_terr_incidents = terr[terr['TargetNationality'] == 'United States']\n",
        "us_property_damage = us_terr_incidents.groupby('Year', as_index=False)['DamagedPropertyValue'].sum()\n",
        "us_property_damage['DamagedPropertyValue'] = us_property_damage['DamagedPropertyValue'].divide(1e6).apply(np.ceil)\n",
        "\n",
        "# Find US Casuality\n",
        "us_casuality = us_terr_incidents.groupby('Year', as_index=False)['Casualities'].sum()['Casualities']\n",
        "\n",
        "\n",
        "# Draw plot\n",
        "years = us_property_damage['Year'].tolist()\n",
        "us_pd = us_property_damage['DamagedPropertyValue'].tolist()\n",
        "\n",
        "fig, ax = plt.subplots(2,1,figsize = (15,12))\n",
        "ax[0].bar(years,us_pd,color = \"red\")\n",
        "ax[0].set(xlabel='Year',ylabel='Millions',title='Damaged Property Value by year',xticks=years)\n",
        "ax[0].set_xticklabels(years, rotation=90, ha=\"center\")\n",
        "ax[0].grid(False)\n",
        "ax[1].bar(years,us_casuality,color = \"red\")\n",
        "ax[1].set(xlabel='Year',ylabel='Person',title='Casualities by year',xticks=years)\n",
        "ax[1].set_xticklabels(years, rotation=90, ha=\"center\")\n",
        "ax[1].grid(False)\n",
        "plt.subplots_adjust(hspace = 0.5)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH7Pq9GHN4PX",
        "colab_type": "text"
      },
      "source": [
        "### Which US target that was attacked mostly?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJTSLRrZC4M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find a target based on attack times\n",
        "pd_and_at_map = us_terr_incidents.groupby('TargetType',axis=0)['AttackType'].value_counts().unstack().fillna(0)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(pd_and_at_map, annot=True, fmt=\".1f\",cmap=\"Reds\")\n",
        "plt.title(\"The most target and attack type based on incidents\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hfsIq8COCM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Find a target based on Damage Property value\n",
        "pd_per_at = us_terr_incidents.groupby(['TargetType','AttackType'],axis=0, as_index=False)['DamagedPropertyValue'].sum()\n",
        "pd_per_at.sort_values('DamagedPropertyValue', inplace=True, ascending=False)\n",
        "pd_per_at['DamagedPropertyValue'] = pd_per_at['DamagedPropertyValue'].divide(1e6).apply(np.ceil)\n",
        "p_d_per_at = pd_per_at.pivot(index='TargetType',columns='AttackType',values='DamagedPropertyValue').fillna(0)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(p_d_per_at, annot=True, fmt=\".1f\",cmap=\"Reds\")\n",
        "plt.title(\"The most target and attack type based on damaged property value\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzaYj-dFFzqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find a target based on casuality\n",
        "c_per_at = us_terr_incidents.groupby(['TargetType','AttackType'],axis=0, as_index=False)['Casualities'].sum()\n",
        "c_per_at.sort_values('Casualities', inplace=True, ascending=False)\n",
        "p_c_per_at = c_per_at.pivot(index='TargetType',columns='AttackType',values='Casualities').fillna(0)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(p_c_per_at, annot=True, fmt=\".0f\",cmap=\"Reds\")\n",
        "plt.title(\"The most target and attack type based on casuality\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIGRMOmMzQsD",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Geo Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI7PwgMU2Qv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instal dependencies\n",
        "!pip install git+git://github.com/geopandas/geopandas.git\n",
        "!apt install proj-bin libproj-dev libgeos-dev\n",
        "!pip install git+git://github.com/ResidentMario/geoplot.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM3I0o7d2XCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import geopandas as gpd\n",
        "import geoplot as gplt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_LqCdZOIg7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Geo Data\n",
        "geo_data = gpd.read_file('/content/drive/My Drive/FTMLE - Tonga/Data/geo_data/ne_10m_admin_0_countries.shp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viGDU13u-Pkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_data['CONTINENT'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNb4XOEb2ctl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select only relavant data i.e. Country & geometry\n",
        "# geo_data = geo_data[['SOVEREIGNT', 'geometry']]\n",
        "geo_data = geo_data[(geo_data['CONTINENT'] == 'Asia')][['SOVEREIGNT', 'geometry']]\n",
        "geo_data.columns = ['country', 'geometry']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3JVsL7N2Yst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "geo_data['country'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg-GFrp15H5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create terrorist data\n",
        "terr_data = terr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDJKiSwhI7_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Make sure that the Country columns in two datasets are matching3\n",
        "for c in terr_data['Country'].value_counts().index:\n",
        "  if c not in geo_data['country'].value_counts().index:\n",
        "    print(c)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr9LKX8pJtu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace unmatched values\n",
        "replace_country = {'United States': 'United States of America',\n",
        "                   'Northern Ireland': 'United Kingdom',\n",
        "                   'Great Britain': 'United Kingdom',\n",
        "                   'Macau':'China',\n",
        "                   'Hong Kong':'China',\n",
        "                   'St. Lucia': 'Saint Lucia',\n",
        "                   'Czech Republic': 'Czechia'}\n",
        "\n",
        "\n",
        "terr_data['Country'].replace(replace_country, inplace = True)\n",
        "\n",
        "terr_data = terr_data[terr_data['Country'].isin(geo_data['country'].value_counts().index)]\n",
        "terr_data['Region'].unique()\n",
        "terr_data = terr_data[terr_data['Region'] == 'Middle East & North Africa']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My4L5dPK38OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Get incidents per country\n",
        "#  plot_data = terr_data.groupby('Country')[['ID']].count()\n",
        "#  plot_data.columns = ['IncidentCount']\n",
        "print(plot_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEITBUz7Ld-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge two datasets to add geometry info\n",
        "# plot_data = plot_data.merge(geo_data, how= 'right', left_index = True, right_on = 'country')\n",
        "# plot_data.dropna(inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sND82WxcNZ2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the Pandas DataFrame to a GeoPandas DataFrame\n",
        "plot_data = gpd.GeoDataFrame(plot_data, geometry = 'geometry')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VYWGY5vNBBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot \n",
        "gplt.choropleth(plot_data, hue = 'IncidentCount', cmap = 'Reds', figsize = (10,10), legend=True)\n",
        "\n",
        "\n",
        "#Add data label to the map\n",
        "plot_data['coords'] = plot_data['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
        "plot_data['coords'] = [coords[0] for coords in plot_data['coords']]\n",
        "top_5_data = plot_data.head(5)\n",
        "for _, data in top_5_data.iterrows():\n",
        "\n",
        "  plt.text(x = data['coords'][0], y = data['coords'][1], \n",
        "           s = data['country'], ha = 'center', color = 'red')\n",
        "  plt.text(x = data['coords'][0], y = data['coords'][1] - 2, \n",
        "          s = f\"Incident: {data['IncidentCount']:.2f}\", ha = 'center', color = 'red')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}